{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c836a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('training.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Loading dataset...\")\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "\n",
    "logger.info(\"Cleaning data...\")\n",
    "data.dropna(inplace=True) \n",
    "data = data.drop_duplicates()  \n",
    "logger.info(f\"Dataset shape after cleaning: {data.shape}\")\n",
    "\n",
    "\n",
    "logger.info(\"Performing feature engineering...\")\n",
    "data['Log_Amount'] = np.log1p(data['Amount'])  \n",
    "data['Hour'] = (data['Time'] // 3600) % 24  \n",
    "data['Time_Diff'] = data['Time'].diff().fillna(0)  \n",
    "features = ['V' + str(i) for i in range(1, 29)] + ['Log_Amount', 'Hour', 'Time_Diff']\n",
    "X = data[features]\n",
    "y = data['Class']\n",
    "logger.info(f\"Features used: {features}\")\n",
    "\n",
    "logger.info(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "logger.info(f\"Feature matrix shape after scaling: {X_scaled.shape}\")\n",
    "\n",
    "logger.info(\"Applying SMOTE for class imbalance...\")\n",
    "smote = SMOTE(sampling_strategy=0.1, random_state=42)  \n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "logger.info(f\"Resampled dataset shape: {X_resampled.shape}\")\n",
    "\n",
    "logger.info(\"Splitting data into train/test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "logger.info(f\"Training set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [10, 20],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [3, 6],\n",
    "            'learning_rate': [0.05, 0.1]\n",
    "        }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMClassifier(random_state=42, verbose=-1),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'max_depth': [3, 6],\n",
    "            'learning_rate': [0.05, 0.1]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_model_name = ''\n",
    "results = []\n",
    "\n",
    "for name, config in models.items():\n",
    "    logger.info(f\"Training {name}...\")\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        config['model'],\n",
    "        config['params'],\n",
    "        n_iter=5, \n",
    "        cv=3,      \n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    model = search.best_estimator_\n",
    "\n",
    "    logger.info(f\"Evaluating {name} on test set...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Best Parameters': search.best_params_,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    })\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    logger.info(f\"{name} completed in {(end_time - start_time).total_seconds()} seconds\")\n",
    "\n",
    "logger.info(\"\\nModel Comparison:\")\n",
    "for result in results:\n",
    "    logger.info(f\"\\n{result['Model']}:\")\n",
    "    logger.info(f\"Best Parameters: {result['Best Parameters']}\")\n",
    "    logger.info(f\"Precision: {result['Precision']:.4f}\")\n",
    "    logger.info(f\"Recall: {result['Recall']:.4f}\")\n",
    "    logger.info(f\"F1-Score: {result['F1-Score']:.4f}\")\n",
    "    logger.info(f\"ROC-AUC: {result['ROC-AUC']:.4f}\")\n",
    "\n",
    "logger.info(f\"\\nBest Model: {best_model_name} with F1-Score: {best_f1:.4f}\")\n",
    "\n",
    "logger.info(\"Saving best model and scaler...\")\n",
    "joblib.dump(best_model, 'best_fraud_detection_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "logger.info(\"Training completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
